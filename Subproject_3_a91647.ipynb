{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "143d6c92",
   "metadata": {},
   "source": [
    "# Subproject 3 – Clustering for Iris datasets\n",
    "Fasegun Babatunde Oyeniyi (a91647)\n",
    "\n",
    "Machine Learning – M.Sc. in Electrical and Computer Engineering, ISE,\n",
    "University of Algrave, Faro, Portugal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099257bc",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this subproject, clustering algorithms are used on the Iris dataset to group samples based on feature values rather than class labels during training. The core approach is K-Means clustering, utilizing feature scaling due to its distance-based nature. The Elbow Method is used to establish the appropriate number of clusters, while Principal Component Analysis (PCA) is employed for visualization. Finally, the clustering results are evaluated by calculating the Silhouette Score from the clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0bed6a",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae682a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd81d20f",
   "metadata": {},
   "source": [
    "Loading the Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65561e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb51436",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "\n",
    "Before preprocessing, I examined the Iris dataset's basic structure and sample rows. I then used summary statistics and basic distribution plots to determine how each feature was distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913a0483",
   "metadata": {},
   "source": [
    "i extracted the features out from the datsaet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d4ba67",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659dbb6e",
   "metadata": {},
   "source": [
    "i used the shape property to get the shape of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca38a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  shape of the data\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2e2dc2",
   "metadata": {},
   "source": [
    "I created a pandas Dataframe table that showed the feature names and the the first 5 rows using .head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b702033b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(iris.feature_names)\n",
    "\n",
    "df_features = pd.DataFrame(X, columns=iris.feature_names)\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0392f818",
   "metadata": {},
   "source": [
    "Iris data features visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9c64a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.boxplot([df_features[col].values for col in feature_names], tick_labels=feature_names)\n",
    "plt.title(\"Feature Distributions\")\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca04582",
   "metadata": {},
   "source": [
    "Petal features vary far more than sepal features, and sepal width has a few outliers. Since K-Means is distance-based, these bigger ranges would end up driving the clustering, therefore I standardize the features first to keep them on the same scale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5998e2",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "\n",
    "Before running K-Means, I standardized the Iris features because the variables have different ranges and K-Means relies on distance. Without scaling, the larger-variation features (especially the petal measurements) would dominate the clustering. There, i used StandardScaler to transform each features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627aeb44",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a0dab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "features_scaled = scaler.fit_transform(X)\n",
    "\n",
    "features_scaled = pd.DataFrame(features_scaled, columns=iris.feature_names)\n",
    "features_scaled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f66caa9",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5d4050",
   "metadata": {},
   "source": [
    "## K-Means: Elbow Method\n",
    "\n",
    "Before doing clustering for the Iris data using means, when defining the n_clusters parameter for the KMeans() method intead of using an arbitary value, i used the elbow method to get the right value of clusters in the Iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e73ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "inertias = []\n",
    "k_range = range(1, 11)\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(\n",
    "        n_clusters=k,\n",
    "        random_state=42,\n",
    "        n_init=10\n",
    "    )\n",
    "    kmeans.fit(features_scaled)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "\n",
    "k_values = np.array(list(k_range))\n",
    "inertias_np = np.array(inertias, dtype=float)\n",
    "\n",
    "points = np.column_stack((k_values, inertias_np))\n",
    "\n",
    "p1, p2 = points[0], points[-1]\n",
    "line_vec = p2 - p1\n",
    "line_vec = line_vec / np.linalg.norm(line_vec)\n",
    "\n",
    "vec_from_p1 = points - p1\n",
    "proj = (vec_from_p1 @ line_vec)[:, None] * line_vec\n",
    "perp = vec_from_p1 - proj\n",
    "distances = np.linalg.norm(perp, axis=1)\n",
    "\n",
    "k_value = int(k_values[np.argmax(distances)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef13946",
   "metadata": {},
   "source": [
    "## Calculating the Clusters using k from above\n",
    "\n",
    "I used the number of cluster derived from using the elbow method which wich will be the n_clusters.  The n_init runs the K-Means 10 times to find the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5282d561",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(\n",
    "    n_clusters=k_value,\n",
    "    random_state=42,\n",
    "    n_init=10\n",
    ")\n",
    "\n",
    "derived_clusters = kmeans.fit_predict(features_scaled)\n",
    "derived_clusters \n",
    "derived = pd.DataFrame()\n",
    "derived[\"derived\"] = derived_clusters\n",
    "derived\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bc77f4",
   "metadata": {},
   "source": [
    "# PCA (Principal Component Analysis)\n",
    "\n",
    "PCA stands for Principal Conponent Analysis, a technique that is used in Machine Learning for reducing the dimentionality of features (reduction from large features to smaller features) while keelping as much deatils as possible. the first principal components has the most variantion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b6fd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "\n",
    "features_pca = pca.fit_transform(features_scaled)\n",
    "\n",
    "features_pca = pd.DataFrame(\n",
    "    features_pca,\n",
    "    columns=pca.get_feature_names_out()\n",
    ")\n",
    "\n",
    "features_pca.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56907e6c",
   "metadata": {},
   "source": [
    "## Visualization of PCAs for the clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeac9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for cluster in np.unique(derived_clusters):\n",
    "    plt.scatter(\n",
    "        features_pca.loc[derived_clusters == cluster, \"pca0\"],\n",
    "        features_pca.loc[derived_clusters == cluster, \"pca1\"],\n",
    "        label=f\"Cluster {cluster}\"\n",
    "    )\n",
    "\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.title(\"PCA K-Means Clusters\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899c910d",
   "metadata": {},
   "source": [
    "## Visualization: True Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753fc8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = iris.target\n",
    "target_names = iris.target_names\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for label in np.unique(y):\n",
    "    plt.scatter(\n",
    "        features_pca.loc[y == label, \"pca0\"],\n",
    "        features_pca.loc[y == label, \"pca1\"],\n",
    "        label=target_names[label]\n",
    "    )\n",
    "\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.title(\"PCA Iris Data (True Species)\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac91ab8f",
   "metadata": {},
   "source": [
    "## Clusters Evaluation using Silhouette Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3fed20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_samples\n",
    "import pandas as pd\n",
    "\n",
    "sample_scores = silhouette_samples(features_scaled, derived_clusters)\n",
    "\n",
    "cluster_scores = (\n",
    "    pd.DataFrame({\"clusters\": derived_clusters, \"sil\": sample_scores})\n",
    "      .groupby(\"clusters\")[\"sil\"]\n",
    "      .mean()\n",
    ")\n",
    "\n",
    "print(cluster_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b728c4ba",
   "metadata": {},
   "source": [
    "Comparison with Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993c713a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "comparison = pd.crosstab(\n",
    "    derived_clusters,\n",
    "    y,\n",
    "    rownames=[\"Cluster\"],\n",
    "    colnames=[\"True Species\"]\n",
    ")\n",
    "\n",
    "display(comparison)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
